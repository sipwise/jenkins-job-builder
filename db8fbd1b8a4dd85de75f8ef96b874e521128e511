{
  "comments": [
    {
      "key": {
        "uuid": "1abeadc6_1f847409",
        "filename": "jenkins_jobs/builder.py",
        "patchSetId": 12
      },
      "lineNbr": 701,
      "author": {
        "id": 1054
      },
      "writtenOn": "2014-08-29T14:02:09Z",
      "side": 1,
      "message": "This essentially means that if only one job failed out of several hundred, the cache won\u0027t be updated.\n\nShould we do it that way? Or should we simply raise the exception from within the parallel decorator if it\u0027s not being caught by the function being processed.",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_d509fd95",
        "filename": "jenkins_jobs/builder.py",
        "patchSetId": 12
      },
      "lineNbr": 701,
      "author": {
        "id": 8212
      },
      "writtenOn": "2014-09-05T09:05:26Z",
      "side": 1,
      "message": "I think it\u0027s better to update all the successful caches, and after that, then raise the exception, that way all the jobs that were updated correctly will be updated in the cache (probably that\u0027s what I thought when I did not raise directly in the threaded app).\n\nWhat do you think?",
      "parentUuid": "1abeadc6_1f847409",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_7faba874",
        "filename": "jenkins_jobs/builder.py",
        "patchSetId": 12
      },
      "lineNbr": 705,
      "author": {
        "id": 1054
      },
      "writtenOn": "2014-08-29T14:02:09Z",
      "side": 1,
      "message": "Any reason not to do this as part of the job update inside the parallel_update_job method?\n\nPresumably if the call to \u0027self.jenkins.update_job(job.name, job.output())\u0027 in the parallel_update_job method succeeds, we can just update the cache.",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_b52d6100",
        "filename": "jenkins_jobs/builder.py",
        "patchSetId": 12
      },
      "lineNbr": 705,
      "author": {
        "id": 8212
      },
      "writtenOn": "2014-09-05T09:05:26Z",
      "side": 1,
      "message": "Because I\u0027m not sure of the thread safety of the cache itself, that way only one thread updated the cache at any time.",
      "parentUuid": "1abeadc6_7faba874",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_df683cf7",
        "filename": "jenkins_jobs/builder.py",
        "patchSetId": 12
      },
      "lineNbr": 707,
      "author": {
        "id": 1054
      },
      "writtenOn": "2014-08-29T14:02:09Z",
      "side": 1,
      "message": "I\u0027m wondering if it would be better to move this to be handled by a call to atexit with the CacheStorage object?\n\nThe more I think about it, the better it seems to try to have the CacheStorage object handle how the cache is saved. I\u0027ll submit a proposed patch to change the current behaviour here rather than try to discuss mixing it in with this change.",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_b0ebaf11",
        "filename": "jenkins_jobs/builder.py",
        "patchSetId": 12
      },
      "lineNbr": 707,
      "author": {
        "id": 8212
      },
      "writtenOn": "2014-09-05T09:05:26Z",
      "side": 1,
      "message": "In this specific case I agree on the atexit, but if you leave the saving to the cache, you have to still let the code that uses the cache to have a way to ensure that the cache is saved before continuing. Mmm, well, in this case I will not care, as I know (at least in the current execution) that noone is going to read the file before I finish.\n\nLet\u0027s discuss it on the new change though",
      "parentUuid": "1abeadc6_df683cf7",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_65897f25",
        "filename": "tests/parallel/test_parallel.py",
        "patchSetId": 12
      },
      "lineNbr": 44,
      "author": {
        "id": 6039
      },
      "writtenOn": "2014-08-28T23:58:17Z",
      "side": 1,
      "message": "N.B.: this is not guaranteed to sleep for a full `secs` seconds, it is only guaranteed to not sleep for more than `secs` seconds.",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_397b1a7c",
        "filename": "tests/parallel/test_parallel.py",
        "patchSetId": 12
      },
      "lineNbr": 44,
      "author": {
        "id": 8212
      },
      "writtenOn": "2014-08-29T08:08:38Z",
      "side": 1,
      "message": "Yes, I know, and it might break on really slow machines or if stopped during the tests. Not sure if there\u0027s a sane alternative, I\u0027m open to suggestions.",
      "parentUuid": "1abeadc6_65897f25",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_1acc82ba",
        "filename": "tests/parallel/test_parallel.py",
        "patchSetId": 12
      },
      "lineNbr": 44,
      "author": {
        "id": 1054
      },
      "writtenOn": "2014-08-29T14:02:09Z",
      "side": 1,
      "message": "Would the following work here?\n\n def wait(secs):\n    end \u003d begin \u003d time.time()\n    remainder \u003d secs\n    while slept \u003c secs:\n        time.sleep(remainder)\n        end \u003d time.time()\n        slept \u003d end - begin\n        remainder \u003d secs - slept",
      "parentUuid": "1abeadc6_397b1a7c",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_35979149",
        "filename": "tests/parallel/test_parallel.py",
        "patchSetId": 12
      },
      "lineNbr": 44,
      "author": {
        "id": 8212
      },
      "writtenOn": "2014-09-05T09:05:26Z",
      "side": 1,
      "message": "I don\u0027t think so, because I\u0027m using very small values (actually 1) for the sleep function, and you are using the sleep function also, so in the best case it\u0027s the same. For big values of secs, it might be better, but it does not ensure either that it won\u0027t sleep more than it you specified, as it\u0027s relying on the same process (it just uses slices of one second each time it sleeps instead of sleeping the whole way through).",
      "parentUuid": "1abeadc6_1acc82ba",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_c5b6d3f8",
        "filename": "tests/parallel/test_parallel.py",
        "patchSetId": 12
      },
      "lineNbr": 48,
      "author": {
        "id": 6039
      },
      "writtenOn": "2014-08-28T23:58:17Z",
      "side": 1,
      "message": "Why not use n_workers\u003d0?",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "1abeadc6_794d923d",
        "filename": "tests/parallel/test_parallel.py",
        "patchSetId": 12
      },
      "lineNbr": 48,
      "author": {
        "id": 8212
      },
      "writtenOn": "2014-08-29T08:08:38Z",
      "side": 1,
      "message": "Because that means that I do not know a priori how many threads it will be using, it might be one or 100.\nThat way I can ensure that on a standard machine under standard load it will take a little more than one second (I\u0027m testing for less than 5 though).\n\nI also don\u0027t want to increment too much the time it takes to run the tests.",
      "parentUuid": "1abeadc6_c5b6d3f8",
      "revId": "db8fbd1b8a4dd85de75f8ef96b874e521128e511",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543",
      "unresolved": false
    }
  ]
}